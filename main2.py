import tensorflow as tf
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import os
import json
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import Input
from tensorflow.keras.models import Model

def load_image_labels(json_file_path):
    with open(json_file_path, 'r', encoding='utf-8') as json_file:
        return json.load(json_file)

def create_label_mapping(labels):
    unique_labels = sorted(set(labels.values()))
    label_to_number = {label: i for i, label in enumerate(unique_labels)}
    return label_to_number, len(unique_labels)

def preprocess_images(image_directory, image_labels, label_to_number):
    image_data = []
    labels = []
    for file_name, label in image_labels.items():
        image_path = os.path.join(image_directory, file_name)
        image = load_img(image_path, target_size=(32, 32))  # Direct resize
        image = img_to_array(image) / 255.0  # Normalize pixel values
        
        image_data.append(image)
        labels.append(label_to_number[label])  # Convert label to numerical format
    
    return np.array(image_data), np.array(labels)

def augment_data(X_train, y_train):
    datagen = ImageDataGenerator(
        rotation_range=20,
        zoom_range=0.15,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.15,
        horizontal_flip=True,
        fill_mode="nearest")
    datagen.fit(X_train)
    return datagen

def define_compile_model(number_of_classes):
    # Define a VGG-like model
    base_model = VGG16(include_top=False, input_tensor=Input(shape=(32, 32, 3)), weights=None)
    x = base_model.output
    x = tf.keras.layers.Flatten()(x)
    x = tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)
    predictions = tf.keras.layers.Dense(number_of_classes, activation='softmax')(x)
    
    model = Model(inputs=base_model.input, outputs=predictions)
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

def compute_class_weights(y_train):
    from sklearn.utils.class_weight import compute_class_weight
    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)
    return dict(enumerate(class_weights))

def main(image_directory, json_file_path):
    image_labels = load_image_labels(json_file_path)
    label_to_number, number_of_classes = create_label_mapping(image_labels)
    
    X, y = preprocess_images(image_directory, image_labels, label_to_number)
    y = to_categorical(y, num_classes=number_of_classes)
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    class_weights = compute_class_weights(np.argmax(y_train, axis=1))
    
    datagen = augment_data(X_train, y_train)
    
    model = define_compile_model(number_of_classes)
    
    # Learning rate scheduler
    def lr_schedule(epoch):
        lr = 1e-3
        if epoch > 10:
            lr *= 0.5e-3
        elif epoch > 20:
            lr *= 1e-3
        elif epoch > 30:
            lr *= 0.5e-3
        elif epoch > 40:
            lr *= 1e-4
        print('Learning rate: ', lr)
        return lr
    lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)

    # Fit the model on the batches generated by datagen.flow().
    history = model.fit(
        datagen.flow(X_train, y_train, batch_size=32),
        epochs=10,  # You may increase the number of epochs
        validation_data=(X_test, y_test),
        class_weight=class_weights,
        callbacks=[lr_scheduler]
    )

    # Save the model in the TensorFlow's default SavedModel format
    model.save('traffic_sign_model.keras')

    predictions = model.predict(X_test)
    predicted_classes = np.argmax(predictions, axis=1)

    number_to_label = {i: label for label, i in label_to_number.items()}
    predicted_labels = [number_to_label[pred] for pred in predicted_classes]

    # Consider printing some results or evaluations here
    unique_labels, counts = np.unique(predicted_labels, return_counts=True)
    for label, count in zip(unique_labels, counts):
        print(f'{label}: {count}')
    print(f'Total predictions: {len(predicted_labels)}')

if __name__ == "__main__":
    image_directory = 'utjelzotablak'
    json_file_path = 'descriptions.json'
    main(image_directory, json_file_path)

